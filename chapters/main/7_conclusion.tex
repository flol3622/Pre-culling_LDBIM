\chapter{Conclusion and future work} \label{ch:conclusion}
% restating idea and goals/ question in one text
% - To what extent can LDBIM geometry be culled to be streamed to lightweight viewers?
% - Can existing semantics and ontologies be used to feed possible culling algorithms?
This thesis has explored the feasibility of culling geometry from an \ac{ldbim} graph for streaming to lightweight viewers. The goal was to minimize the volume of data within the viewer itself, as existing in-viewer culling techniques encounter processing limitations when the scene continues to expand in size, particularly when managing non-active parts of the scene. Two primary questions were therefore posed:

\begin{enumerate}
    \item To what extent can LDBIM geometry be culled to be streamed to lightweight viewers? (Section \ref{subsec:rq1})
    \item Can existing semantics and ontologies be utilized to inform potential culling algorithms? (Section \ref{subsec:rq2})
\end{enumerate}

Both questions were initially explored by reviewing the current state of the art in the field of Semantic Web and culling algorithms. This evolved into a hands-on approach, where the development of a prototype led to new insights.

\section{Object-level Culling}
Employing existing ontologies such as \ac{fog} and \ac{omg} enabled the definition of geometry at the object level, which identified the smallest units that can be culled . As a result, this thesis did not address culling techniques such as back-face culling, as these are handled by the viewer itself, not the database. These ontologies, although not specifically explored in this thesis, also allow the linking of auxiliary geometry files, such as texture maps, to the entities. Future research could explore the possibilities of implementing these auxiliary geometry data in the viewer, utilizing the \ac{omg} level 2 data pattern, thereby enhancing the visual quality of the resulting scene.

\section{Culling Algorithms}
Three culling algorithms were proposed, each performing culling operations in radically different ways, showcasing the possibilities of culling by constructing \ac{sparql} queries.

The first algorithm (Section \ref{sec:inSituWKT}) utilizes the \ac{wkt} serialization of \ac{bot} rooms to evaluate GeoSPARQL functions. This approach highlighted the lack of 3D operations in GeoSPARQL, indicating a crucial need in the \ac{aec} industry for a standard for 3D spatial operations in \ac{sparql}, which, as of now, does not exist.

The second algorithm (Section \ref{sec:inViewer}) leveraged the viewer's 3D engine capabilities to perform 3D operations not feasible with the first algorithm. It utilized raytracing to determine the room in which the observer was located. Although this algorithm offloaded 3D operations from the database to the viewer, which appears counter-intuitive to the thesis's objective, the operations were optimized to use as little computing power as possible by performing the raytracing only on a subset of rooms in the scene.

The third algorithm (Section \ref{sec:inQuery}) proposes a method to implement 3D operations in the form of string operations within the \ac{sparql} query itself. As \ac{sparql} string operations are limited, a custom JavaScript function was added to the \ac{sparql} endpoint. However, the implementation is specific to the endpoint used in this thesis, GraphDB, as no standard exists for custom functions in \ac{sparql} endpoints. The developed function is also limited to the analysis of the OBJ geometry format, but similar functions could be developed for other formats.

All options utilized the \ac{bot} ontology to zoom out from the object-level to cull at the room-level, leveraging the inherent underlying hierarchy of \ac{bim} models which is described in the graph using the \ac{bot} ontology. It was found to produce coherent results and reduce the computational resources needed for the culling. However, this hierarchy is only important when inside the building and becomes irrelevant when outside the building. Further research could explore the potential of culling algorithms for scenarios outside the building.

\section{Modular approach}
% - modular approach:
% -- successfull showcasing 
% -- shows it actually works
% -- room for further improvement, in very step, from cache mangagement algorithm to when th equery has to run again
% -- https://github.com/flol3622/Pre-culling_LDBIM#demo

The modular approach (Chapter \ref{ch:modularApproach}) presented in this thesis' prototype (Chapter \ref{ch:prototype}) was found to be successful in showcasing the feasibility of culling geometry from an \ac{ldbim} graph. It also highlighted the need for further research in each step of the process, from the cache management to the moment when the query has to run again. But showcases a strong foundation for future development and research.

\subsection{Prototype}
The main features of the prototype are showcased at:\\
\url{https://github.com/flol3622/Pre-culling_LDBIM#demo}\\
The following features are presented:

\begin{itemize}
    \item \textbf{Basic use case:} The basic use case is presented where the entire building is loaded with a maximum number of entities set to 20. The user can navigate through the building and entities are loaded on demand. The user can also change the maximum number of entities to be loaded at once.
    \item \textbf{Different sources and formats:} The prototype can load different sources and formats. A database of abstract shapes is selected which holds STL, OBJ and GLTF geometry files as literals or as links to external files on GitHub. (Section \ref{sec:viewerRequirements})
    \item \textbf{Semantic-driven filtering:} With the aid of semantics, the user can filter the entities to load in the viewer. This example filters the entities to only show the ones with \mintinline{sparql}|rdf:type prod:Window|.
    \item \textbf{Semantic-driven colorization:} Semantics associated with each entity can be used to colorize the entities in the viewer. This example colorizes the entities based on their \mintinline{sparql}|flupke:color| property which holds a color code. (Sections \ref{sec:visualSemantic}, \ref{sec:semanticVis})
    \item \textbf{In-query, OBJ-string analytics} A first culling algorithm is showcased where the \mintinline{sparql}|bot:Space| entities are filtered based on their OBJ definition, which is analyzed by the endpoint using a string operation. The cache management mechanism is also visualized as the viewer's scene does not exceed an entity count of 20. (Section \ref{sec:inQuery})
    \item \textbf{In situ, GeoSPARQL} This second culling algorithm uses GeoSPARQL functions. As the GeoSPARQL functions are limited to 2D space, the viewer hovering over a \mintinline{sparql}|bot:Space| triggers the loading of this last. (Section \ref{sec:inSituWKT})
\end{itemize}

The source code is available at:\\
\url{https://github.com/flol3622/LDBIM-viewer}\\


% - database:
% -- starintg from existing db from Mads Holten: relativaly easy
% -- but only one found, no bigger datasets
% -- missing usefull relations as adjacent space, the floors associated with the rooms
