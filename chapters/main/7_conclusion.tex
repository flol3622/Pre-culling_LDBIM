\chapter{Conclusion and future work} \label{ch:conclusion}
% restating idea and goals/ question in one text
% - To what extent can LDBIM geometry be culled to be streamed to lightweight viewers?
% - Can existing semantics and ontologies be used to feed possible culling algorithms?
This thesis has explored the feasibility of culling geometry from an \ac{ldbim} graph for streaming to lightweight viewers. The goal was to minimize the volume of data within the viewer itself, as existing in-viewer culling techniques encounter processing limitations when the scene continues to expand in size, particularly when managing non-active parts of the scene. Two primary questions were therefore posed:

\begin{enumerate}
    \item To what extent can LDBIM geometry be culled to be streamed to lightweight viewers? (Section \ref{subsec:rq1})
    \item Can existing semantics and ontologies be utilized to inform potential culling algorithms? (Section \ref{subsec:rq2})
\end{enumerate}

Both questions were initially explored by reviewing the current state of the art in the field of Semantic Web and culling algorithms. This evolved into a hands-on approach, where the development of a prototype led to new insights.

\section{Object-level Culling}
Employing existing ontologies such as \ac{fog} and \ac{omg} enabled the definition of geometry at the object level, which identified the smallest units that can be culled . As a result, this thesis did not address culling techniques such as back-face culling, as these are handled by the viewer itself, not the database. These ontologies, although not specifically explored in this thesis, also allow the linking of auxiliary geometry files, such as texture maps, to the entities. Future research could explore the possibilities of implementing these auxiliary geometry data in the viewer, utilizing the \ac{omg} level 2 data pattern, thereby enhancing the visual quality of the resulting scene.

\section{Culling Algorithms}
Three culling algorithms were proposed, each performing culling operations in radically different ways, showcasing the possibilities of culling by constructing \ac{sparql} queries.

The first algorithm (Section \ref{sec:inSituWKT}) utilizes the \ac{wkt} serialization of \ac{bot} rooms to evaluate GeoSPARQL functions. This approach highlighted the lack of 3D operations in GeoSPARQL, indicating a crucial need in the \ac{aec} industry for a standard for 3D spatial operations in \ac{sparql}, which, as of now, does not exist.

The second algorithm (Section \ref{sec:inViewer}) leveraged the viewer's 3D engine capabilities to perform 3D operations not feasible with the first algorithm. It utilized raytracing to determine the room in which the observer was located. Although this algorithm offloaded 3D operations from the database to the viewer, which appears counter-intuitive to the thesis's objective, the operations were optimized to use as little computing power as possible by performing the raytracing only on a subset of rooms in the scene.

The third algorithm (Section \ref{sec:inQuery}) proposes a method to implement 3D operations in the form of string operations within the \ac{sparql} query itself. As \ac{sparql} string operations are limited, a custom JavaScript function was added to the \ac{sparql} endpoint. However, the implementation is specific to the endpoint used in this thesis, GraphDB, as no standard exists for custom functions in \ac{sparql} endpoints. The developed function is also limited to the analysis of the OBJ geometry format, but similar functions could be developed for other formats.

All options utilized the \ac{bot} ontology to zoom out from the object-level to cull at the room-level, leveraging the inherent underlying hierarchy of \ac{bim} models which is described in the graph using the \ac{bot} ontology. It was found to produce coherent results and reduce the computational resources needed for the culling. However, this hierarchy is only important when inside the building and becomes irrelevant when outside the building. Further research could explore the potential of culling algorithms for scenarios outside the building.

\section{Modular approach and prototype}
% - modular approach:
% -- successfull showcasing 
% -- shows it actually works
% -- room for further improvement, in very step, from cache mangagement algorithm to when th equery has to run again
% -- https://github.com/flol3622/Pre-culling_LDBIM#demo

The modular approach (Chapter \ref{ch:modularApproach}) presented in this thesis' prototype (Chapter \ref{ch:prototype}) was found to be successful in showcasing the feasibility of culling geometry from an \ac{ldbim} graph. It also highlighted the need for further research in each step of the process, from the cache management to the moment when the query has to run again. But showcases a strong foundation for future development and research.

\newpage
The main features of the prototype are showcased at:\\
\url{https://github.com/flol3622/Pre-culling_LDBIM#demo}\\
The following features are presented:

\begin{itemize}
    \item \textbf{Basic use case:} The basic use case is presented where the entire building is loaded with a maximum number of entities set to 20. The user can navigate through the building and entities are loaded on demand. The user can also change the maximum number of entities to be loaded at once.
    \item \textbf{Different sources and formats:} The prototype can load different sources and formats. A database of abstract shapes is selected which holds STL, OBJ and GLTF geometry files as literals or as links to external files on GitHub. (Section \ref{sec:viewerRequirements})
    
    To achieve this goal, the existing ontologies \ac{fog} and \ac{omg} were used. However, these were stretched to their limits, as newer ontologies and semantics are needed to fully leverage the potential and versatility of Linked Data. The developed prototype highlighted the need for additional data about each geometry description, such as orientation and scale, which can differ between file formats.

    \item \textbf{Semantic-driven filtering:} With the aid of semantics, the user can filter the entities to load in the viewer. This example filters the entities to only show the ones with \mintinline{sparql}|rdf:type prod:Window|.
    \item \textbf{Semantic-driven colorization:} Semantics associated with each entity can be used to colorize the entities in the viewer. This example colorizes the entities based on their \mintinline{sparql}|flupke:color| property which holds a color code. (Sections \ref{sec:visualSemantic}, \ref{sec:semanticVis})
    \item \textbf{In-query, OBJ-string analytics} A first culling algorithm is showcased where the \mintinline{sparql}|bot:Space| entities are filtered based on their OBJ definition, which is analyzed by the endpoint using a string operation. The cache management mechanism is also visualized as the viewer's scene does not exceed an entity count of 20. (Section \ref{sec:inQuery})
    \item \textbf{In situ, GeoSPARQL} This second culling algorithm uses GeoSPARQL functions. As the GeoSPARQL functions are limited to 2D space, the viewer hovering over a \mintinline{sparql}|bot:Space| triggers the loading of this last. (Section \ref{sec:inSituWKT})
\end{itemize}

The source code is available at: \url{https://github.com/flol3622/LDBIM-viewer}


\section{Database}
% - database:
% -- starintg from existing db from Mads Holten: relativaly easy
% -- but only one found, no bigger datasets
% -- missing usefull relations as adjacent space, the floors associated with the rooms

The database used in this thesis was based on the work of Mads Holten Rasmussen \cite{}, which was found to be relatively easy to adapt to the needs of this thesis as it already contained geometrical (obj geometry), spatial (\ac{wkt} serialisation) and realtaional (\ac{bot} relations) data. Despite its usefullness, the limited size prevented the evaluation of the performance of the culling algorithms on larger datasets. The lack of larger datasets was also found to be a general problem in the field of \ac{ldbim}, as no other was found during this research. Besides its size, the dataset was also found to be missing some relations, such as the adjacent spaces and the floors associated with the rooms. These relations are important for the culling algorithms as they are used to zoom out from the object-level to the room-level.

\section{Conclusion}
% - conclusion:
% -- culling is possible
% -- but still a lot of work to do
% -- but a good foundation for future work

This thesis has shown that culling \ac{ldbim} graphs to reduce the size of the scene a lightweight viewer has to manage in order to visualise a building model stored in a database using Semantic Web technologies is possible. It also presented multiple approaches to perform the culling, each with its own advantages and disadvantages, as well as a modular approach to implement the whole process in a web viewer. This technology has proven to be a viable solution to the demanding needs of the \ac{aec} industry when visualizing large \ac{bim} models. And it provides a solid foundation for further development in various use cases and scenarios requiring 3D visual representation.